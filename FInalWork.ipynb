{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 159\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image, bounding_box\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Split data into train and test sets\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m train_images, test_images, train_bounding_boxes, test_bounding_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounding_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Convert NumPy arrays to PyTorch tensors\u001b[39;00m\n\u001b[1;32m    163\u001b[0m train_images_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(train_images)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2649\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2649\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2305\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2302\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2309\u001b[0m     )\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset, random_split\n",
    "# Other necessary imports for your specific dataset and preprocessing\n",
    "import os, time, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import matplotlib.patches as patches\n",
    "from torchvision import ops\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_folder = '/home/m3-learning/Documents/myML/Training/preprocessed_data/'\n",
    "file_list = os.listdir(data_folder)\n",
    "\n",
    "file_pairs = {}\n",
    "for file in file_list:\n",
    "    if file.endswith('_img.npz'):\n",
    "        identifier = file.split('_')[0]\n",
    "        if identifier not in file_pairs:\n",
    "            file_pairs[identifier] = {'img': file, 'box': None}\n",
    "        else:\n",
    "            file_pairs[identifier]['img'] = file\n",
    "    elif file.endswith('_box.npz'):\n",
    "        identifier = file.split('_')[0]\n",
    "        if identifier not in file_pairs:\n",
    "            file_pairs[identifier] = {'img': None, 'box': file}\n",
    "        else:\n",
    "            file_pairs[identifier]['box'] = file\n",
    "\n",
    "# Load image and bounding box data\n",
    "# Load image and bounding box data\n",
    "images = []\n",
    "bounding_boxes = []\n",
    "\n",
    "for identifier, files in file_pairs.items():\n",
    "    img_file = files['img']\n",
    "    box_file = files['box']\n",
    "    if img_file and box_file:\n",
    "        img_data = np.load(os.path.join(data_folder, img_file))['arr_0']\n",
    "        box_data = np.load(os.path.join(data_folder, box_file))['arr_0']\n",
    "        images.append(img_data)\n",
    "        bounding_boxes.append(box_data)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "images = np.array(images)\n",
    "bounding_boxes = np.array(bounding_boxes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_shape,num_boxes = 4, num_classes = 5):\n",
    "        super(FCNN, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    #     # # Calculate the input size for the fully connected layers after convolution\n",
    "    #     # conv_output_size = self._get_conv_output(input_shape)\n",
    "\n",
    "    #     self.fc_layers = nn.Sequential(\n",
    "    #         nn.Flatten(),\n",
    "    #         nn.Linear(128*8*8, 2048),\n",
    "    #         nn.ReLU(),\n",
    "    #         nn.Linear(2048, 128),\n",
    "    #         nn.ReLU(),\n",
    "    #         nn.Linear(128, num_classes)\n",
    "            \n",
    "            \n",
    "    #         #nn.Softmax(dim=1)  # Output layer with Softmax activation\n",
    "    #     )\n",
    "    # def forward(self, x):\n",
    "    #     #print(\"Input shape:\", x.shape)  # Print the input shape\n",
    "    #     x = self.conv_layers(x)\n",
    "    #     #print(\"Shape after conv layers:\", x.shape)  # Print the shape after convolutional layers\n",
    "    #     x = self.fc_layers(x)\n",
    "        \n",
    "    #     return x \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_boxes * num_classes)  # Output layer for multiple boxes\n",
    "        )\n",
    "\n",
    "        self.num_boxes = num_boxes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x.view(-1, self.num_boxes, self.num_classes)\n",
    "\n",
    "input_channels = 1\n",
    "input_height = 64\n",
    "input_width = 64\n",
    "\n",
    "# Define the input size based on the input image shape\n",
    "input_shape = input_channels * input_height * input_width\n",
    "\n",
    "# Define your custom dataset\n",
    "# Define your custom dataset\n",
    "class BoundingBoxDataset(Dataset):\n",
    "    def __init__(self, images, bounding_boxes, transform):\n",
    "        self.images = images\n",
    "        self.bounding_boxes = bounding_boxes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        bounding_box = self.bounding_boxes[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)  # Convert numpy array to PIL Image\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Convert bounding box data to tensors\n",
    "        bounding_box = torch.from_numpy(bounding_box).float()\n",
    "\n",
    "        return image, bounding_box\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_images, test_images, train_bounding_boxes, test_bounding_boxes = train_test_split(\n",
    "    images, bounding_boxes, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "train_images_tensor = torch.from_numpy(train_images).float()\n",
    "train_bounding_boxes_tensor = torch.from_numpy(train_bounding_boxes).float()\n",
    "\n",
    "test_images_tensor = torch.from_numpy(test_images).float()\n",
    "test_bounding_boxes_tensor = torch.from_numpy(test_bounding_boxes).float()\n",
    "\n",
    "# Add a channel dimension to grayscale images\n",
    "train_images_tensor = train_images_tensor.unsqueeze(1)  # Adds a channel dimension at index 1\n",
    "test_images_tensor = test_images_tensor.unsqueeze(1)\n",
    "#train_images_tensor = train_images_tensor.repeat(1, 3, 1, 1)  # Repeat the single channel three times\n",
    "#test_images_tensor = test_images_tensor.repeat(1, 3, 1, 1)  # Repeat the single channel three times\n",
    "\n",
    "\n",
    "# Verify the new shapes after adding channel dimension\n",
    "#print(train_images_tensor.shape)\n",
    "#print(test_images_tensor.shape)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create instances of your custom dataset\n",
    "train_dataset = BoundingBoxDataset(train_images, train_bounding_boxes, transform=transform)\n",
    "test_dataset = BoundingBoxDataset(test_images, test_bounding_boxes, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the model and move it to GPU if available\n",
    "device = torch.device(\"cpu\")\n",
    "fcnn_model = FCNN(input_shape=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.min = torch.min(data, dim=0)[0]\n",
    "        self.max = torch.max(data, dim=0)[0]\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "# Define your loss function and optimizer and Scaler\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(fcnn_model.parameters(), lr=0.001)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    fcnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, bounding_boxes in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # No need to flatten the input, keep it as 4D tensor [batch_size, channels, height, width]\n",
    "        outputs = fcnn_model(images)\n",
    "        \n",
    "        loss = criterion(outputs, bounding_boxes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Print predicted bounding box parameters for each batch during training\n",
    "        print(f\"Predicted Bounding Box Parameters (Training):\\n{outputs[0]}\")  # Modify this according to your output structure\n",
    "\n",
    "    # Print training loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluation\n",
    "fcnn_model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, bounding_boxes in test_loader:\n",
    "        outputs = fcnn_model(images)\n",
    "        test_loss += criterion(outputs, bounding_boxes).item()\n",
    "        \n",
    "        # Print predicted bounding box parameters for each batch during testing\n",
    "        print(f\"Predicted Bounding Box Parameters (Testing):\\n{outputs[0]}\")  # Modify this according to your output structure\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader)}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset, random_split\n",
    "# Other necessary imports for your specific dataset and preprocessing\n",
    "import os, time, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import matplotlib.patches as patches\n",
    "from torchvision import ops\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_folder = '/home/m3-learning/Documents/myML/Training/preprocessed_data/'\n",
    "file_list = os.listdir(data_folder)\n",
    "\n",
    "file_pairs = {}\n",
    "for file in file_list:\n",
    "    if file.endswith('_img.npz'):\n",
    "        identifier = file.split('_')[0]\n",
    "        if identifier not in file_pairs:\n",
    "            file_pairs[identifier] = {'img': file, 'box': None}\n",
    "        else:\n",
    "            file_pairs[identifier]['img'] = file\n",
    "    elif file.endswith('_box.npz'):\n",
    "        identifier = file.split('_')[0]\n",
    "        if identifier not in file_pairs:\n",
    "            file_pairs[identifier] = {'img': None, 'box': file}\n",
    "        else:\n",
    "            file_pairs[identifier]['box'] = file\n",
    "\n",
    "# Load image and bounding box data\n",
    "images = []\n",
    "bounding_boxes = []\n",
    "\n",
    "for identifier, files in file_pairs.items():\n",
    "    img_file = files['img']\n",
    "    box_file = files['box']\n",
    "    if img_file and box_file:\n",
    "        img_data = np.load(os.path.join(data_folder, img_file))['arr_0']\n",
    "        box_data = np.load(os.path.join(data_folder, box_file))['arr_0']\n",
    "        images.append(img_data)\n",
    "        bounding_boxes.append(box_data)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "images = np.array(images)\n",
    "bounding_boxes = np.array(bounding_boxes)\n",
    "\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_shape,num_boxes = 4, num_classes = 5):\n",
    "        super(FCNN, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    #     # # Calculate the input size for the fully connected layers after convolution\n",
    "    #     # conv_output_size = self._get_conv_output(input_shape)\n",
    "\n",
    "    #     self.fc_layers = nn.Sequential(\n",
    "    #         nn.Flatten(),\n",
    "    #         nn.Linear(128*8*8, 2048),\n",
    "    #         nn.ReLU(),\n",
    "    #         nn.Linear(2048, 128),\n",
    "    #         nn.ReLU(),\n",
    "    #         nn.Linear(128, num_classes)\n",
    "            \n",
    "            \n",
    "    #         #nn.Softmax(dim=1)  # Output layer with Softmax activation\n",
    "    #     )\n",
    "    # def forward(self, x):\n",
    "    #     #print(\"Input shape:\", x.shape)  # Print the input shape\n",
    "    #     x = self.conv_layers(x)\n",
    "    #     #print(\"Shape after conv layers:\", x.shape)  # Print the shape after convolutional layers\n",
    "    #     x = self.fc_layers(x)\n",
    "        \n",
    "    #     return x \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_boxes * num_classes)  # Output layer for multiple boxes\n",
    "        )\n",
    "\n",
    "        self.num_boxes = num_boxes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x.view(-1, self.num_boxes, self.num_classes)\n",
    "\n",
    "input_channels = 1\n",
    "input_height = 64\n",
    "input_width = 64\n",
    "\n",
    "# Define the input size based on the input image shape\n",
    "input_shape = input_channels * input_height * input_width\n",
    "\n",
    "# Define your custom dataset\n",
    "class BoundingBoxDataset(Dataset):\n",
    "    def __init__(self, images, bounding_boxes,transform):\n",
    "        self.images = images\n",
    "        self.bounding_boxes = bounding_boxes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.bounding_boxes[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_images, test_images, train_bounding_boxes, test_bounding_boxes = train_test_split(\n",
    "    images, bounding_boxes, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "train_images_tensor = torch.from_numpy(train_images).float()\n",
    "train_bounding_boxes_tensor = torch.from_numpy(train_bounding_boxes).float()\n",
    "\n",
    "test_images_tensor = torch.from_numpy(test_images).float()\n",
    "test_bounding_boxes_tensor = torch.from_numpy(test_bounding_boxes).float()\n",
    "\n",
    "# Add a channel dimension to grayscale images\n",
    "train_images_tensor = train_images_tensor.unsqueeze(1)  # Adds a channel dimension at index 1\n",
    "test_images_tensor = test_images_tensor.unsqueeze(1)\n",
    "#train_images_tensor = train_images_tensor.repeat(1, 3, 1, 1)  # Repeat the single channel three times\n",
    "#test_images_tensor = test_images_tensor.repeat(1, 3, 1, 1)  # Repeat the single channel three times\n",
    "\n",
    "\n",
    "# Verify the new shapes after adding channel dimension\n",
    "print(train_images_tensor.shape)\n",
    "print(test_images_tensor.shape)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create instances of your custom dataset\n",
    "train_dataset = BoundingBoxDataset(train_images_tensor, train_bounding_boxes_tensor,transform=transform)\n",
    "test_dataset = BoundingBoxDataset(test_images_tensor, test_bounding_boxes_tensor,transform=transform)\n",
    "\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "fcnn_model = FCNN(input_shape)\n",
    "\n",
    "\n",
    "\n",
    "class MinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.min = torch.min(data, dim=0)[0]\n",
    "        self.max = torch.max(data, dim=0)[0]\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "# Define your loss function and optimizer and Scaler\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(fcnn_model.parameters(), lr=0.001)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    fcnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, bounding_boxes in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # No need to flatten the input, keep it as 4D tensor [batch_size, channels, height, width]\n",
    "        outputs = fcnn_model(images)\n",
    "        \n",
    "        loss = criterion(outputs, bounding_boxes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Print predicted bounding box parameters for each batch during training\n",
    "        print(f\"Predicted Bounding Box Parameters (Training):\\n{outputs[0]}\")  # Modify this according to your output structure\n",
    "\n",
    "    # Print training loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluation\n",
    "fcnn_model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, bounding_boxes in test_loader:\n",
    "        outputs = fcnn_model(images)\n",
    "        test_loss += criterion(outputs, bounding_boxes).item()\n",
    "        \n",
    "        # Print predicted bounding box parameters for each batch during testing\n",
    "        print(f\"Predicted Bounding Box Parameters (Testing):\\n{outputs[0]}\")  # Modify this according to your output structure\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader)}\")      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
